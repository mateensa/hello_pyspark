Introduction: Spark is fast, easy to use, engine for Big-Data processing  
    it has below modules or api's
    
    1.  Streaming
    2.  SQL/ETL
    3.  Machine learning
    4.  Graph Processing
    
    Spark Python API aka pyspark, exposes spark model into python programming model using python API
   
Why use spark when (what is) mapreduce is available? 

What is: 

MapReduce is engine responsible for bigdata processing, in distributed way but parallely. it's a part of Handoop eco-system. 
It  has two components map and reduce aka multi-stage computation system. 
     Map: It takes set of data from source and converts in to tuples (key value pair)
     Reduce: It takes data from Map and reduce it (by applying transformations or cleansing ... ) parallely across clusters.
     
Why: 
    Map writes data into disks, first maps reads data in serialized format and decerilize it (aka. object encryption or decryption) 
    writes to disk in form of tuples, thus making available for reduce. 
    
    Reduce: reads data from Map and does some transformations and writes data again to disk. 
    
Thus map and reduce totally does io  (read/writes to disk) & processing, it does not consider writing data to some place where it does not have read or write frequently (ram).
To avoid this (call it as feature of map-reduce), Spark has been used which does all in memory. 

which means spark reads data from source, keeps it in memory and process it, thus by reducing io requests across hardware and thus its makes faster.


Single Environment

You can use the same single clustered runtime environment for prototyping, ad hoc queries, and deploying your applications leveraging the many ingestion data points offered by the Spark platform.
You can be as low-level as using RDD API directly or leverage higher-level APIs of Spark SQL (Datasets), Spark MLlib (ML Pipelines), Spark GraphX (Graphs) or Spark Streaming (DStreams).
Or use them all in a single application.
The single programming model and execution engine for different kinds of workloads simplify development and deployment architectures.


-------------------------------------------X-----------------------------------------
